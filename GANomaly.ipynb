{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2A+r6aBBEBPuhMXfrwiOx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sxbxn/Furry_Friends/blob/ai_2/GANomaly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nfR2-EcVOt0w"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M0lyeTcO69N",
        "outputId": "6dd596c8-08cd-4ed9-e276-83e5f718015d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq /content/drive/MyDrive/teamproject/Ch04.zip"
      ],
      "metadata": {
        "id": "NnhqNbgpQ7of",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a48e438-a57b-4e54-e3aa-e96c6b6b2819"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace 0/test_img/test/D_61_20120525_IF_0029_NOR_Ch04_20211214_2907.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_encoder_model():\n",
        "    inputs = layers.Input(shape=(224, 224, 3))\n",
        "    x = layers.Conv2D(64, 3, strides=2, padding='same', activation='relu')(inputs)\n",
        "    x = layers.Conv2D(64, 3, strides=1, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(128, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(128, 3, strides=1, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(256, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(256, 3, strides=1, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(512, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(512, 3, strides=1, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(512, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(512, 3, strides=1, padding='same', activation='relu')(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(1024, activation='relu')(x)\n",
        "    outputs = layers.Dense(32, activation='relu')(x)\n",
        "    return Model(inputs=inputs, outputs=outputs)\n"
      ],
      "metadata": {
        "id": "m-ix1F8BPD9u"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_decoder_model():\n",
        "    inputs = layers.Input(shape=(32,))\n",
        "    x = layers.Dense(1024, activation='relu')(inputs)\n",
        "    x = layers.Dense(7*7*512, activation='relu')(x)\n",
        "    x = layers.Reshape((7, 7, 512))(x)\n",
        "    x = layers.Conv2DTranspose(512, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2DTranspose(512, 3, strides=1, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2DTranspose(256, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2DTranspose(256, 3, strides=1, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2DTranspose(128, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2DTranspose(128, 3, strides=1, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2DTranspose(64, 3, strides=1, padding='same', activation='relu')(x)\n",
        "    outputs = layers.Conv2DTranspose(3, 3, strides=2, padding='same', activation='sigmoid')(x)\n",
        "    return Model(inputs=inputs, outputs=outputs)\n"
      ],
      "metadata": {
        "id": "mLRMyMrKPJ7q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the discriminator network\n",
        "def make_discriminator_model():\n",
        "    inputs = layers.Input(shape=(32,))\n",
        "    x = layers.Dense(128, activation='relu')(inputs)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "    return keras.models.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "boy1wh9jPnp2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GANomaly(keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super(GANomaly, self).__init__()\n",
        "    self.encoder = make_encoder_model()\n",
        "    self.decoder = make_decoder_model()\n",
        "    self.discriminator = make_discriminator_model()\n",
        "\n",
        "  def call(self, x): \n",
        "      z = self.encoder(x)  # latent vector.\n",
        "      x_hat = self.decoder(z)\n",
        "      d = self.discriminator(z)\n",
        "      return x_hat, d"
      ],
      "metadata": {
        "id": "Dx7r2q_UQmjB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the losses\n",
        "adversarial_loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "reconstruction_loss = keras.losses.MeanAbsoluteError()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\n",
        "# Define the batch size and number of epochs\n",
        "batch_size = 32\n",
        "num_epochs = 100\n",
        "image_size = (224, 224)"
      ],
      "metadata": {
        "id": "dOjDpuF-Q3yb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_paths = tf.data.Dataset.list_files('/content/0/train_img')\n",
        "\n",
        "# # Define a function to load and preprocess the images\n",
        "# def load_and_preprocess_image(file_path):\n",
        "#     # Load the image\n",
        "#     image = tf.io.read_file(file_path)\n",
        "#     image = tf.image.decode_jpeg(image, channels=3)\n",
        "#     # Resize and normalize the image\n",
        "#     image = tf.image.resize(image, image_size)\n",
        "#     image = image / 255.\n",
        "#     return image\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define a data generator to load and preprocess image data\n",
        "data_generator = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# Load training data from a directory and preprocess it using the data generator\n",
        "train_dataset = data_generator.flow_from_directory('/content/0/train_img', batch_size=32, target_size = image_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJTTjE7tm294",
        "outputId": "80146518-e463-4f2f-ab48-6851a2b0ef7f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6184 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ganomaly = GANomaly() # create the GANomaly model"
      ],
      "metadata": {
        "id": "LEqGe5F4m3im"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFJcGGWiShPU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, batch in enumerate(train_dataset):\n",
        "        images = batch[0]\n",
        "        labels = np.zeros((batch_size, 1))\n",
        "        labels[:batch_size//2] = 1\n",
        "        labels = tf.cast(labels,tf.float32)\n",
        "\n",
        "        # Train discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            generated_image, original_latent = ganomaly(images)\n",
        "            _, generated_latent = ganomaly(generated)\n",
        "            d_loss_real = adversarial_loss(original_latent, labels)\n",
        "            d_loss_fake = adversarial_loss(generated_latent, tf.zeros((batch_size, 1)))\n",
        "            # print(d_loss_real,d_loss_fake)\n",
        "            d_loss_reconstructed = reconstruction_loss(images, generated_image)\n",
        "            # print(d_loss_reconstructed)\n",
        "            d_loss = d_loss_real + d_loss_fake + d_loss_reconstructed\n",
        "        grads = tape.gradient(d_loss, ganomaly.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, ganomaly.trainable_weights))\n",
        "\n",
        "        # Train generator\n",
        "        with tf.GradientTape() as tape:\n",
        "            generated, original_latent = ganomaly(images)\n",
        "            g_loss = adversarial_loss(original_latent, labels) + reconstruction_loss(images, generated)\n",
        "        grads = tape.gradient(g_loss, ganomaly.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, ganomaly.trainable_weights))\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f'Epoch {epoch+1}, Batch {i+1}, D Loss: {d_loss.numpy():.4f}, G Loss: {g_loss.numpy():.4f}')"
      ],
      "metadata": {
        "id": "joQH4WYNOrfG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "4ce3c29c-60cd-4657-af36-ded8185b95d3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 1, D Loss: 7.8096, G Loss: 7.8088\n",
            "Epoch 1, Batch 101, D Loss: 7.7709, G Loss: 7.7722\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-1bb946b80dcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mgenerated_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mganomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mganomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# print(d_loss_real,d_loss_fake)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 )\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0min_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         )\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[1;32m   2174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m     return backend.mean(\n\u001b[0;32m-> 2176\u001b[0;31m         \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2177\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2178\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m   5686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5687\u001b[0m     \u001b[0;31m# Compute cross entropy from probabilities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5688\u001b[0;31m     \u001b[0mbce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5689\u001b[0m     \u001b[0mbce\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5690\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mbce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:Mul]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ganomaly.discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27g5dUfhsHlP",
        "outputId": "5252229e-2ca3-4f89-921a-ef9299b30610"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 32)]              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               4224      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,353\n",
            "Trainable params: 4,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}